{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Obtain data from alex and Kacper \n",
    "- Record a full conversation\n",
    "- Train the model (using tensorflow)\n",
    "- Test it in the main app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 13:11:11.093009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-17 13:11:11.169127: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-17 13:11:11.169589: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-17 13:11:11.294855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 13:11:12.301818: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Constants\n",
    "SR = 16000  # Sample rate\n",
    "DURATION = 10  # Duration of each audio clip in seconds\n",
    "\n",
    "# Function to load and preprocess audio file\n",
    "def preprocess_audio(audio_file):\n",
    "    # Load audio using pydub\n",
    "    audio = AudioSegment.from_file(audio_file)\n",
    "\n",
    "    # Resample audio to SR and convert to mono\n",
    "    audio = audio.set_frame_rate(SR).set_channels(1)\n",
    "\n",
    "    # Convert pydub.AudioSegment to numpy array\n",
    "    audio_array = np.array(audio.get_array_of_samples(), dtype=np.float32)\n",
    "\n",
    "    # Trim or pad audio to DURATION seconds\n",
    "    target_length = int(SR * DURATION)\n",
    "    if len(audio_array) < target_length:\n",
    "        padding = target_length - len(audio_array)\n",
    "        audio_array = np.pad(audio_array, (0, padding), mode='constant')\n",
    "    elif len(audio_array) > target_length:\n",
    "        audio_array = audio_array[:target_length]\n",
    "\n",
    "    # Normalize audio\n",
    "    audio_array /= np.max(np.abs(audio_array))\n",
    "\n",
    "    return audio_array\n",
    "\n",
    "# Function to extract features (e.g., spectrogram)\n",
    "def extract_features(audio_array):\n",
    "    # Compute spectrogram using librosa\n",
    "    S = librosa.feature.melspectrogram(y=audio_array, sr=SR)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    return log_S\n",
    "\n",
    "# Function to process audio files and create DataFrame\n",
    "def process_files(mp3_files):\n",
    "    data = {'audio': [], 'label': []}\n",
    "\n",
    "    for mp3_file in tqdm(mp3_files):\n",
    "        # Determine label from filename\n",
    "        label = os.path.basename(mp3_file).split('_')[0]\n",
    "\n",
    "        # Preprocess audio\n",
    "        audio_array = preprocess_audio(mp3_file)\n",
    "\n",
    "        # Extract features (e.g., spectrogram)\n",
    "        features = extract_features(audio_array)\n",
    "\n",
    "        # Add data to dictionary\n",
    "        data['audio'].append(features)\n",
    "        data['label'].append(label)\n",
    "\n",
    "    # Convert data dictionary to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory = './training/'\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Filter files with .mp3 extension\n",
    "mp3_files = [file for file in files if file.endswith('.mp3')]\n",
    "\n",
    "\n",
    "# Process files to create DataFrame\n",
    "train_df = process_files(mp3_files)\n",
    "\n",
    "#Save DataFrame to CSV file\n",
    "train_df.to_csv('./training/trainining_audio_dataset.csv', index=False)\n",
    "\n",
    "print(\"Audio preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tensorflow training code (use train df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
